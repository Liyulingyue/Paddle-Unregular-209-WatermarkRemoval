{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 百度网盘AI大赛-图像处理挑战赛：水印智能消除赛第16名方案\n",
    "\n",
    "[比赛链接](https://aistudio.baidu.com/aistudio/competition/detail/209/0/introduction)\n",
    "\n",
    "## 比赛介绍\n",
    "日常生活中带有水印的图片很常见，即使是PS专家，也很难快速且不留痕迹的去除水印。而使用智能去除水印的算法，可以快速自动去除图片中的水印。选手需要通过深度学习技术训练模型，对给定的真实场景下采集得到的带有水印的图片进行处理，并最终输出处理后的扫描结果图片。\n",
    "\n",
    "本次比赛希望选手结合当下前沿的图像处理技术与计算机视觉技术，提升模型的训练性能和泛化能力，在保证效果精准的同时，注意模型在实际应用中的性能问题，做到尽可能的小而快。\n",
    "\n",
    "## 技术分析\n",
    "\n",
    "- 模型选择 \n",
    "\n",
    "0. 本次模型来源于[摩尔纹消除赛题第二名方案](https://aistudio.baidu.com/aistudio/projectdetail/3439099)，与基线中使用的Unet相比，都是具有Pixel2Pixel形式的网络结构。整体而言，不管是Unet还是IDRnet在本任务上的表象类似。在Resize到512进行预测的预处理下，UNet得分0.58915，IDR得分0.59762。即IDR效果更好，但是两者差距不大。都是PSNR过低。\n",
    "\n",
    "- 数据增强\n",
    "\n",
    "0. 从数据量的角度来说，本赛题给出的数据量非常巨大，但是可能由于UNet和IDR都过于单薄，通常在1/10个训练集上已经可以收敛。不需要做额外的数据增强操作。\n",
    "\n",
    "1. 在预测时，如果将图片缩放到512再预测，会导致图片损失大量信息。但如果不调整图片尺寸，会导致在模型计算过程中，两个隐藏层的输入输出不对应，可以参考[摩尔纹消除赛题第二名方案](https://aistudio.baidu.com/aistudio/projectdetail/3439099)对图片进行补零，从而尽可能贴近原图的尺寸进行预测。在这种处理之下，PSNR大约提升到36。\n",
    "\n",
    "- loss\n",
    "\n",
    "0. 赛题的评分标准为ms-ssim和psnr，但实际上大家的ms-ssim的差距较小，主要的差别集中在psnr上。加大损失中psnr的系数，并不能显著对于IDR网络和UNet网络提高分数。\n",
    "\n",
    "- checkpoint\n",
    "\n",
    "0. checkpoint保存为model2.pdparams\n",
    "\n",
    "# 代码\n",
    "## 解压数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "! tar -xvf /home/aistudio/data/data142446/bg_images.tar\n",
    "! tar -xvf /home/aistudio/data/data142446/watermark_datasets.part10.tar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 构造数据读取器\n",
    "通过paddle.io.dataset构造读取器，便于读取数据。\n",
    "\n",
    "数据预处理包括：\n",
    "1. 将带有水印和不带水印的图片均转化为(3,512,512)的形状\n",
    "2. 对图片进行归一化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-15T15:24:21.572938Z",
     "iopub.status.busy": "2022-05-15T15:24:21.572211Z",
     "iopub.status.idle": "2022-05-15T15:24:21.584768Z",
     "shell.execute_reply": "2022-05-15T15:24:21.584030Z",
     "shell.execute_reply.started": "2022-05-15T15:24:21.572892Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ntrain_dataset=MyDateset()\\n\\ntrain_dataloader = paddle.io.DataLoader(\\n    train_dataset,\\n    batch_size=16,\\n    shuffle=True,\\n    drop_last=False)\\n\\nfor step, data in enumerate(train_dataloader):\\n    img, label = data\\n    print(step, img.shape, label.shape)\\n    break\\n'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import paddle\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import cv2\n",
    "\n",
    "class MyDateset(paddle.io.Dataset):\n",
    "    def __init__(self, mode = 'train', watermark_dir = '/home/aistudio/watermark_datasets.part8/', bg_dir = '/home/aistudio/bg_images/'):\n",
    "        super(MyDateset, self).__init__()\n",
    "\n",
    "        self.mode = mode \n",
    "        self.watermark_dir = watermark_dir\n",
    "        self.bg_dir = bg_dir\n",
    "\n",
    "        self.train_list = os.listdir(self.watermark_dir)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        item = self.train_list[index]\n",
    "        bg_item = item[:14]+'.jpg'\n",
    "\n",
    "        img = cv2.imread(self.watermark_dir+item)\n",
    "        label = cv2.imread(self.bg_dir+bg_item)\n",
    "\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        label = cv2.cvtColor(label, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        img = paddle.vision.transforms.resize(img, (512,512), interpolation='bilinear')\n",
    "        label = paddle.vision.transforms.resize(label, (512,512), interpolation='bilinear')\n",
    "\n",
    "        img = img.transpose((2,0,1))\n",
    "        label = label.transpose((2,0,1))\n",
    "        \n",
    "        img = img/255\n",
    "        label = label/255\n",
    "\n",
    "        img = paddle.to_tensor(img).astype('float32')\n",
    "        label = paddle.to_tensor(label).astype('float32')\n",
    "\n",
    "        return img,label\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.train_list)\n",
    "\n",
    "# 对dataloader进行测试\n",
    "'''\n",
    "train_dataset=MyDateset()\n",
    "\n",
    "train_dataloader = paddle.io.DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=16,\n",
    "    shuffle=True,\n",
    "    drop_last=False)\n",
    "\n",
    "for step, data in enumerate(train_dataloader):\n",
    "    img, label = data\n",
    "    print(step, img.shape, label.shape)\n",
    "    break\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 定义loss\n",
    "同样秉承着拿来主义的思想，从[图像评价指标PSNR、SSIM以及MS-SSIM\n",
    "](https://aistudio.baidu.com/aistudio/projectdetail/1844007?channelType=0&channel=0)复制一份MSSSIM代码过来。\n",
    "\n",
    "~看不看得懂代码不重要，重要是看得懂文字，明白大佬已经写好了一个现成的直接调用的loss函数~\n",
    "\n",
    "当然，仅有MSSSIM是不够的，还可以再根据[通过Sub-Pixel实现图像超分辨率](https://www.paddlepaddle.org.cn/documentation/docs/zh/practices/cv/super_resolution_sub_pixel.html#sub-pixel)写一个PSNR的损失函数。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-15T15:25:48.953969Z",
     "iopub.status.busy": "2022-05-15T15:25:48.953420Z",
     "iopub.status.idle": "2022-05-15T15:25:48.982524Z",
     "shell.execute_reply": "2022-05-15T15:25:48.981533Z",
     "shell.execute_reply.started": "2022-05-15T15:25:48.953929Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "import paddle\n",
    "import paddle.nn.functional as F\n",
    "\n",
    "def gaussian1d(window_size, sigma):\n",
    "    ###window_size = 11\n",
    "    x = paddle.arange(window_size,dtype='float32')\n",
    "    x = x - window_size//2\n",
    "    gauss = paddle.exp(-x ** 2 / float(2 * sigma ** 2))\n",
    "    # print('gauss.size():', gauss.size())\n",
    "    ### torch.Size([11])\n",
    "    return gauss / gauss.sum()\n",
    "\n",
    "def create_window(window_size, sigma, channel):\n",
    "    _1D_window = gaussian1d(window_size, sigma).unsqueeze(1)\n",
    "    _2D_window = _1D_window.mm(_1D_window.t()).unsqueeze(0).unsqueeze(0)\n",
    "    # print('2d',_2D_window.shape)\n",
    "    # print(window_size, sigma, channel)\n",
    "    return _2D_window.expand([channel,1,window_size,window_size])\n",
    "\n",
    "def _ssim(img1, img2, window, window_size, channel=3 ,data_range = 255.,size_average=True,C=None):\n",
    "    # size_average for different channel\n",
    "\n",
    "    padding = window_size // 2\n",
    "\n",
    "    mu1 = F.conv2d(img1, window, padding=padding, groups=channel)\n",
    "    mu2 = F.conv2d(img2, window, padding=padding, groups=channel)\n",
    "    # print(mu1.shape)\n",
    "    # print(mu1[0,0])\n",
    "    # print(mu1.mean())\n",
    "    mu1_sq = mu1.pow(2)\n",
    "    mu2_sq = mu2.pow(2)\n",
    "    mu1_mu2 = mu1 * mu2\n",
    "    sigma1_sq = F.conv2d(img1 * img1, window, padding=padding, groups=channel) - mu1_sq\n",
    "    sigma2_sq = F.conv2d(img2 * img2, window, padding=padding, groups=channel) - mu2_sq\n",
    "    sigma12 = F.conv2d(img1 * img2, window, padding=padding, groups=channel) - mu1_mu2\n",
    "    if C ==None:\n",
    "        C1 = (0.01*data_range) ** 2\n",
    "        C2 = (0.03*data_range) ** 2\n",
    "    else:\n",
    "        C1 = (C[0]*data_range) ** 2\n",
    "        C2 = (C[1]*data_range) ** 2\n",
    "    # l = (2 * mu1_mu2 + C1) / (mu1_sq + mu2_sq + C1)\n",
    "    # ssim_map = ((2 * mu1_mu2 + C1) * (2 * sigma12 + C2)) / ((mu1_sq + mu2_sq + C1) * (sigma1_sq + sigma2_sq + C2))\n",
    "    sc = (2 * sigma12 + C2) / (sigma1_sq + sigma2_sq + C2)\n",
    "    lsc = ((2 * mu1_mu2 + C1) / (mu1_sq + mu2_sq + C1))*sc\n",
    "\n",
    "    if size_average:\n",
    "        ### ssim_map.mean()是对这个tensor里面的所有的数值求平均\n",
    "        return lsc.mean()\n",
    "    else:\n",
    "        # ## 返回各个channel的值\n",
    "        return lsc.flatten(2).mean(-1),sc.flatten(2).mean(-1)\n",
    "\n",
    "def ms_ssim(\n",
    "    img1, img2,window, data_range=255, size_average=True, window_size=11, channel=3, sigma=1.5, weights=None, C=(0.01, 0.03)\n",
    "):\n",
    "\n",
    "    r\"\"\" interface of ms-ssim\n",
    "    Args:\n",
    "        img1 (torch.Tensor): a batch of images, (N,C,[T,]H,W)\n",
    "        img2 (torch.Tensor): a batch of images, (N,C,[T,]H,W)\n",
    "        data_range (float or int, optional): value range of input images. (usually 1.0 or 255)\n",
    "        size_average (bool, optional): if size_average=True, ssim of all images will be averaged as a scalar\n",
    "        win_size: (int, optional): the size of gauss kernel\n",
    "        win_sigma: (float, optional): sigma of normal distribution\n",
    "        win (torch.Tensor, optional): 1-D gauss kernel. if None, a new kernel will be created according to win_size and win_sigma\n",
    "        weights (list, optional): weights for different levels\n",
    "        K (list or tuple, optional): scalar constants (K1, K2). Try a larger K2 constant (e.g. 0.4) if you get a negative or NaN results.\n",
    "    Returns:\n",
    "        torch.Tensor: ms-ssim results\n",
    "    \"\"\"\n",
    "    if not img1.shape == img2.shape:\n",
    "        raise ValueError(\"Input images should have the same dimensions.\")\n",
    "\n",
    "    # for d in range(len(img1.shape) - 1, 1, -1):\n",
    "    #     img1 = img1.squeeze(dim=d)\n",
    "    #     img2 = img2.squeeze(dim=d)\n",
    "\n",
    "    if not img1.dtype == img2.dtype:\n",
    "        raise ValueError(\"Input images should have the same dtype.\")\n",
    "\n",
    "    if len(img1.shape) == 4:\n",
    "        avg_pool = F.avg_pool2d\n",
    "    elif len(img1.shape) == 5:\n",
    "        avg_pool = F.avg_pool3d\n",
    "    else:\n",
    "        raise ValueError(f\"Input images should be 4-d or 5-d tensors, but got {img1.shape}\")\n",
    "\n",
    "    smaller_side = min(img1.shape[-2:])\n",
    "\n",
    "    assert smaller_side > (window_size - 1) * (2 ** 4), \"Image size should be larger than %d due to the 4 downsamplings \" \\\n",
    "                                                        \"with window_size %d in ms-ssim\" % ((window_size - 1) * (2 ** 4),window_size)\n",
    "\n",
    "    if weights is None:\n",
    "        weights = [0.0448, 0.2856, 0.3001, 0.2363, 0.1333]\n",
    "    weights = paddle.to_tensor(weights)\n",
    "\n",
    "    if window is None:\n",
    "        window = create_window(window_size, sigma, channel)\n",
    "    assert window.shape == [channel, 1, window_size, window_size], \" window.shape error\"\n",
    "\n",
    "    levels = weights.shape[0] # 5\n",
    "    mcs = []\n",
    "    for i in range(levels):\n",
    "        ssim_per_channel, cs =  _ssim(img1, img2, window=window, window_size=window_size,\n",
    "                                       channel=3, data_range=data_range,C=C, size_average=False)\n",
    "        if i < levels - 1:\n",
    "            mcs.append(F.relu(cs))\n",
    "            padding = [s % 2 for s in img1.shape[2:]]\n",
    "            img1 = avg_pool(img1, kernel_size=2, padding=padding)\n",
    "            img2 = avg_pool(img2, kernel_size=2, padding=padding)\n",
    "\n",
    "    ssim_per_channel = F.relu(ssim_per_channel)  # (batch, channel)\n",
    "    mcs_and_ssim = paddle.stack(mcs + [ssim_per_channel], axis=0)  # (level, batch, channel) 按照等级堆叠\n",
    "    ms_ssim_val = paddle.prod(mcs_and_ssim ** weights.reshape([-1, 1, 1]), axis=0) # level 相乘\n",
    "    print(ms_ssim_val.shape)\n",
    "    if size_average:\n",
    "        return ms_ssim_val.mean()\n",
    "    else:\n",
    "        # 返回各个channel的值\n",
    "        return ms_ssim_val.flatten(2).mean(1)\n",
    "\n",
    "\n",
    "class SSIMLoss(paddle.nn.Layer):\n",
    "   \"\"\"\n",
    "   1. 继承paddle.nn.Layer\n",
    "   \"\"\"\n",
    "   def __init__(self, window_size=11, channel=3, data_range=255., sigma=1.5):\n",
    "       \"\"\"\n",
    "       2. 构造函数根据自己的实际算法需求和使用需求进行参数定义即可\n",
    "       \"\"\"\n",
    "       super(SSIMLoss, self).__init__()\n",
    "       self.data_range = data_range\n",
    "       self.C = [0.01, 0.03]\n",
    "       self.window_size = window_size\n",
    "       self.channel = channel\n",
    "       self.sigma = sigma\n",
    "       self.window = create_window(self.window_size, self.sigma, self.channel)\n",
    "       # print(self.window_size,self.window.shape)\n",
    "   def forward(self, input, label):\n",
    "       \"\"\"\n",
    "       3. 实现forward函数，forward在调用时会传递两个参数：input和label\n",
    "           - input：单个或批次训练数据经过模型前向计算输出结果\n",
    "           - label：单个或批次训练数据对应的标签数据\n",
    "           接口返回值是一个Tensor，根据自定义的逻辑加和或计算均值后的损失\n",
    "       \"\"\"\n",
    "       # 使用Paddle中相关API自定义的计算逻辑\n",
    "       # output = xxxxx\n",
    "       # return output\n",
    "       return 1-_ssim(input, label,data_range = self.data_range,\n",
    "                      window = self.window, window_size=self.window_size, channel=3,\n",
    "                      size_average=True,C=self.C)\n",
    "\n",
    "class MS_SSIMLoss(paddle.nn.Layer):\n",
    "   \"\"\"\n",
    "   1. 继承paddle.nn.Layer\n",
    "   \"\"\"\n",
    "   def __init__(self,data_range=255., channel=3, window_size=11, sigma=1.5):\n",
    "       \"\"\"\n",
    "       2. 构造函数根据自己的实际算法需求和使用需求进行参数定义即可\n",
    "       \"\"\"\n",
    "       super(MS_SSIMLoss, self).__init__()\n",
    "       self.data_range = data_range\n",
    "       self.C = [0.01, 0.03]\n",
    "       self.window_size = window_size\n",
    "       self.channel = channel\n",
    "       self.sigma = sigma\n",
    "       self.window = create_window(self.window_size, self.sigma, self.channel)\n",
    "       # print(self.window_size,self.window.shape)\n",
    "   def forward(self, input, label):\n",
    "       \"\"\"\n",
    "       3. 实现forward函数，forward在调用时会传递两个参数：input和label\n",
    "           - input：单个或批次训练数据经过模型前向计算输出结果\n",
    "           - label：单个或批次训练数据对应的标签数据\n",
    "           接口返回值是一个Tensor，根据自定义的逻辑加和或计算均值后的损失\n",
    "       \"\"\"\n",
    "       # 使用Paddle中相关API自定义的计算逻辑\n",
    "       # output = xxxxx\n",
    "       # return output\n",
    "       return 1-ms_ssim(input, label, data_range=self.data_range,\n",
    "                      window = self.window, window_size=self.window_size, channel=self.channel,\n",
    "                      size_average=True,  sigma=self.sigma,\n",
    "                      weights=None, C=self.C)\n",
    "\n",
    "class PSNRLoss(paddle.nn.Layer):\n",
    "   def __init__(self):\n",
    "       super(PSNRLoss, self).__init__()\n",
    "\n",
    "   def forward(self, input, label):\n",
    "       return 100 - 20 * paddle.log10( ((input - label)**2).mean(axis = [1,2,3])**-0.5 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 网络在AIDR_arch中定义，直接导入\n",
    "from AIDR_arch import AIDR\n",
    "model = AIDR(num_c=96)\n",
    "model.train()\n",
    "\n",
    "train_dataset=MyDateset(watermark_dir = '/home/aistudio/watermark_datasets.part10/')\n",
    "\n",
    "# 需要接续之前的模型重复训练可以取消注释\n",
    "param_dict = paddle.load('./model.pdparams')\n",
    "model.load_dict(param_dict)\n",
    "\n",
    "train_dataloader = paddle.io.DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=12,\n",
    "    shuffle=True,\n",
    "    drop_last=False)\n",
    "\n",
    "losspsnr = PSNRLoss()\n",
    "lossfn = SSIMLoss(window_size=3,data_range=1)\n",
    "\n",
    "max_epoch=20\n",
    "scheduler = paddle.optimizer.lr.CosineAnnealingDecay(learning_rate=0.00001, T_max=max_epoch)\n",
    "opt = paddle.optimizer.Adam(learning_rate=scheduler, parameters=model.parameters())\n",
    "\n",
    "now_step=0\n",
    "for epoch in range(max_epoch):\n",
    "    for step, data in enumerate(train_dataloader):\n",
    "        now_step+=1\n",
    "\n",
    "        img, label = data\n",
    "        pre = model(img)\n",
    "        loss1 = lossfn(pre,label).mean()\n",
    "        loss2 = losspsnr(pre,label).mean()\n",
    "        loss = (loss1+loss2/50)/2\n",
    "\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        opt.clear_gradients()\n",
    "        if now_step%100==0:\n",
    "            print(\"epoch: {}, batch: {}, loss is: {}\".format(epoch, step, loss.mean().numpy()))\n",
    "\n",
    "paddle.save(model.state_dict(), 'model2.pdparams')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 打包提交\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 压缩可提交文件\n",
    "! zip submit.zip model2.pdparams *.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 查看预测结果（可选、非常耗时）\n",
    "是不是想知道自己训练后的网络去除水印之后的图片到底长啥样？直接下载测试集A看看效果吧~\n",
    "\n",
    "### 下载测试集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "! wget https://staticsns.cdn.bcebos.com/amis/2022-4/1649745356784/watermark_test_datasets.zip\n",
    "! unzip -oq watermark_test_datasets.zip\n",
    "! rm -rf watermark_test_datasets.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 在测试集上预测"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "! python predict.py watermark_test_datasets/images results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "请点击[此处](https://ai.baidu.com/docs#/AIStudio_Project_Notebook/a38e5576)查看本环境基本用法.  <br>\n",
    "Please click [here ](https://ai.baidu.com/docs#/AIStudio_Project_Notebook/a38e5576) for more detailed instructions. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "py35-paddle1.2.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
